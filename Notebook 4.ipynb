{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T13:46:34.065996Z",
     "start_time": "2019-03-25T13:46:33.834724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144a2d5679bd4e569bd4adafd52e6b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MagicsControllerWidget(children=(Tab(children=(ManageSessionWidget(children=(HTML(value='<br/>'), HTML(value='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added endpoint http://10.34.14.129:8999\n",
      "Starting Spark application\n"
     ]
    },
    {
     "ename": "LivyClientTimeoutException",
     "evalue": "Session 164 did not start up in 60 seconds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLivyClientTimeoutException\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m/etc/Applications/Anaconda3/lib/python3.7/site-packages/sparkmagic/livyclientlib/livysession.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlivy_session_startup_timeout_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLivyClientTimeoutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/etc/Applications/Anaconda3/lib/python3.7/site-packages/sparkmagic/livyclientlib/livysession.py\u001b[0m in \u001b[0;36mwait_for_idle\u001b[0;34m(self, seconds_to_wait)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mLivyClientTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLivyClientTimeoutException\u001b[0m: Session 164 did not reach idle status in time. Current status is starting.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLivyClientTimeoutException\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m/etc/Applications/Anaconda3/lib/python3.7/site-packages/hdijupyterutils/ipywidgetfactory.py\u001b[0m in \u001b[0;36msubmit_clicked\u001b[0;34m(self, button)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msubmit_clicked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbutton\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_widget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/etc/Applications/Anaconda3/lib/python3.7/site-packages/sparkmagic/controllerwidget/createsessionwidget.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark_controller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             self.ipython_display.send_error(\"\"\"Could not add session with\n",
      "\u001b[0;32m/etc/Applications/Anaconda3/lib/python3.7/site-packages/sparkmagic/livyclientlib/sparkcontroller.py\u001b[0m in \u001b[0;36madd_session\u001b[0;34m(self, name, endpoint, skip_if_exists, properties)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_livy_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_session_id_for_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/etc/Applications/Anaconda3/lib/python3.7/site-packages/sparkmagic/livyclientlib/livysession.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLivyClientTimeoutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 raise LivyClientTimeoutException(u\"Session {} did not start up in {} seconds.\"\n\u001b[0;32m--> 133\u001b[0;31m                                                  .format(self.id, conf.livy_session_startup_timeout_seconds()))\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sessions_info_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLivyClientTimeoutException\u001b[0m: Session 164 did not start up in 60 seconds."
     ]
    }
   ],
   "source": [
    "%reload_ext sparkmagic.magics\n",
    "%manage_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:21.553760Z",
     "start_time": "2019-03-25T15:01:21.524553Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, FloatType, IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:25.763182Z",
     "start_time": "2019-03-25T15:01:22.483658Z"
    }
   },
   "outputs": [],
   "source": [
    "#Reading the joined parquet file \n",
    "df1 = spark.read.parquet(\"/Fannie-Mae/2016/FNMA_2016_Join_result_test.parquet/part*\")\n",
    "df2 = spark.read.parquet(\"/Fannie-Mae/2017/FNMA_2017_Join_result_test.parquet/part*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:31.728459Z",
     "start_time": "2019-03-25T15:01:31.486044Z"
    }
   },
   "outputs": [],
   "source": [
    "#Renaming the ForeclosureDate column of 2016 to Default\n",
    "df1 = df1.withColumnRenamed('ForeclosureDate','Default')\n",
    "#Renaming the ForeclosureDate column of 2017 to Default\n",
    "df2 = df2.withColumnRenamed('ForeclosureDate','Default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:32.670937Z",
     "start_time": "2019-03-25T15:01:32.435397Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"Default\",when(col(\"Default\").isNull(),0).otherwise(1))\n",
    "df2 = df2.withColumn(\"Default\",when(col(\"Default\").isNull(),0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:33.702238Z",
     "start_time": "2019-03-25T15:01:33.466893Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df1.drop('LoanID','Channel','SellerName','OrDate','FirstPayment','FTHomeBuyer','LoanPurpose','PropertyType','OccStatus','PropertyState','ProductType','RelMortInd','Servicer','MaturityDate','CurDelStatus','ModFlag','ZeroBalEffDate','LastInstallDate','DispositionDate','PricipleForgiven','RMWPF','FPWA','ServicingIndicator','OrLTV','Zip','MortInsPerc','CoCreditScore','MortInsType','CurrInterestRate','CAUPB','MSA','ForeclosureCost','RepairCost','AssetRecCost','MiscCostsPF','ATFHP','NetSaleProceeds','CreditEnhProceeds','RPMWP','OtherForePro','NonInterestUPB','ReportingDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:35.802526Z",
     "start_time": "2019-03-25T15:01:35.564038Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop('LoanID','Channel','SellerName','OrDate','FirstPayment','FTHomeBuyer','LoanPurpose','PropertyType','OccStatus','PropertyState','ProductType','RelMortInd','Servicer','MaturityDate','CurDelStatus','ModFlag','ZeroBalEffDate','LastInstallDate','DispositionDate','PricipleForgiven','RMWPF','FPWA','ServicingIndicator','OrLTV','Zip','MortInsPerc','CoCreditScore','MortInsType','CurrInterestRate','CAUPB','MSA','ForeclosureCost','RepairCost','AssetRecCost','MiscCostsPF','ATFHP','NetSaleProceeds','CreditEnhProceeds','RPMWP','OtherForePro','NonInterestUPB','ReportingDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:37.613920Z",
     "start_time": "2019-03-25T15:01:37.379697Z"
    }
   },
   "outputs": [],
   "source": [
    "df_2016 = df1.na.fill(0)\n",
    "df_2017 = df2.na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:40.441608Z",
     "start_time": "2019-03-25T15:01:39.179994Z"
    }
   },
   "outputs": [],
   "source": [
    "## Let's stratify the data since we have a small amount of Foreclosures\n",
    "positive_count_2016 = df_2016.filter(df_2016['Default'] == 1.0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:42.154725Z",
     "start_time": "2019-03-25T15:01:42.124336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149"
     ]
    }
   ],
   "source": [
    "positive_count_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:46.571923Z",
     "start_time": "2019-03-25T15:01:44.308515Z"
    }
   },
   "outputs": [],
   "source": [
    "positive_count_2017 = df_2017.filter(df_2017['Default'] == 1.0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:50.278401Z",
     "start_time": "2019-03-25T15:01:50.243164Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115"
     ]
    }
   ],
   "source": [
    "positive_count_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:56.784457Z",
     "start_time": "2019-03-25T15:01:56.039113Z"
    }
   },
   "outputs": [],
   "source": [
    "data_size_2016 = df_2016.count()\n",
    "strat_data_2016 = df_2016.sampleBy('Default', fractions={0: float(positive_count_2016)/ data_size_2016, 1: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:01:57.997590Z",
     "start_time": "2019-03-25T15:01:57.756565Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[OrInterestRate: double, OrUnpaidPrinc: int, OrLoanTerm: int, OrCLTV: double, NumBorrow: double, DTIRat: double, CreditScore: double, NumUnits: int, LoanAge: int, MonthsToMaturity: double, AdMonthsToMaturity: double, ZeroBalCode: double, Default: int]"
     ]
    }
   ],
   "source": [
    "strat_data_2016.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:02.901079Z",
     "start_time": "2019-03-25T15:01:59.620327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Default  count\n",
      "0        1    149\n",
      "1        0    147"
     ]
    }
   ],
   "source": [
    "print(strat_data_2016.groupby('Default').count().toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:06.367683Z",
     "start_time": "2019-03-25T15:02:04.106391Z"
    }
   },
   "outputs": [],
   "source": [
    "data_size_2017 = df_2017.count()\n",
    "strat_data_2017 = df_2017.sampleBy('Default', fractions={0: float(positive_count_2017)/ data_size_2017, 1: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:08.114722Z",
     "start_time": "2019-03-25T15:02:07.867983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[LoanAge: int, MonthsToMaturity: float, AdMonthsToMaturity: float, ZeroBalCode: float, Default: int, OrInterestRate: float, OrUnpaidPrinc: int, OrLoanTerm: int, OrCLTV: float, NumBorrow: float, DTIRat: float, CreditScore: float, NumUnits: int]"
     ]
    }
   ],
   "source": [
    "strat_data_2017.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:14.874328Z",
     "start_time": "2019-03-25T15:02:09.588253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Default  count\n",
      "0        1    115\n",
      "1        0    116"
     ]
    }
   ],
   "source": [
    "print(strat_data_2017.groupby('Default').count().toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:17.479152Z",
     "start_time": "2019-03-25T15:02:17.451451Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = strat_data_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:19.012660Z",
     "start_time": "2019-03-25T15:02:18.986504Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = strat_data_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:20.582779Z",
     "start_time": "2019-03-25T15:02:20.556318Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:22.358710Z",
     "start_time": "2019-03-25T15:02:22.116175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[OrInterestRate: double, OrUnpaidPrinc: int, OrLoanTerm: int, OrCLTV: double, NumBorrow: double, DTIRat: double, CreditScore: double, NumUnits: int, LoanAge: int, MonthsToMaturity: double, AdMonthsToMaturity: double, ZeroBalCode: double, Default: int]"
     ]
    }
   ],
   "source": [
    "train_data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:24.082561Z",
     "start_time": "2019-03-25T15:02:23.842417Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_cols_2016 = df_2016.drop('Default').drop('id').columns\n",
    "assembler_2016 = VectorAssembler(inputCols=feature_cols_2016, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:25.719922Z",
     "start_time": "2019-03-25T15:02:25.483126Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol='Default', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:27.352259Z",
     "start_time": "2019-03-25T15:02:27.114558Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler_2016, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:28.332694Z",
     "start_time": "2019-03-25T15:02:28.306323Z"
    }
   },
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.maxIter, [1, 10, 100]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:02:29.891597Z",
     "start_time": "2019-03-25T15:02:29.651657Z"
    }
   },
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol='Default', predictionCol='prediction'),\n",
    "                          numFolds=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:03:41.166312Z",
     "start_time": "2019-03-25T15:02:31.251806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 69.308086"
     ]
    }
   ],
   "source": [
    "time_s = time()\n",
    "cv_model = crossval.fit(train_data)\n",
    "time_e = time()\n",
    "\n",
    "print ('Total training time: %f' % (time_e - time_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:03:47.011253Z",
     "start_time": "2019-03-25T15:03:46.981112Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_metrics(predictions_and_labels):\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    print('Precision of True ', metrics.precision(1))\n",
    "    print('Precision of False', metrics.precision(0))\n",
    "    print('Recall of True    ', metrics.recall(1))\n",
    "    print('Recall of False   ', metrics.recall(0))\n",
    "    print('F-1 Score         ', metrics.fMeasure())\n",
    "    print('Confusion Matrix\\n', metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:03:50.087823Z",
     "start_time": "2019-03-25T15:03:49.852291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[LoanAge: int, MonthsToMaturity: float, AdMonthsToMaturity: float, ZeroBalCode: float, Default: int, OrInterestRate: float, OrUnpaidPrinc: int, OrLoanTerm: int, OrCLTV: float, NumBorrow: float, DTIRat: float, CreditScore: float, NumUnits: int]"
     ]
    }
   ],
   "source": [
    "test_data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:03:56.449592Z",
     "start_time": "2019-03-25T15:03:54.172912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Accuracy: 0.969680"
     ]
    }
   ],
   "source": [
    "predictions = cv_model.transform(test_data)\n",
    "accuracy = cv_model.getEvaluator().evaluate(predictions)\n",
    "print('F1 Accuracy: %f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:06.843938Z",
     "start_time": "2019-03-25T15:04:06.606642Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_and_labels = predictions.select(\"prediction\", \"Default\").rdd.map(lambda r: (float(r[0]), float(r[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-25T15:04:21.600499Z",
     "start_time": "2019-03-25T15:04:16.205886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of True  0.990909090909091\n",
      "Precision of False 0.9504132231404959\n",
      "Recall of True     0.9478260869565217\n",
      "Recall of False    0.9913793103448276\n",
      "F-1 Score          0.9696969696969697\n",
      "Confusion Matrix\n",
      " [[115.   1.]\n",
      " [  6. 109.]]"
     ]
    }
   ],
   "source": [
    "print_metrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
