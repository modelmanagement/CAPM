{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, FloatType, IntegerType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing user to hdfs such that it can access files in the hdfs\n",
    "os.environ[\"HADOOP_USER_NAME\"] = \"hdfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAll((\n",
    "    (\"spark.task.maxFailures\", \"10\"),\n",
    "    (\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\"),\n",
    "    (\"spark.sql.execution.arrow.enabled\", \"true\"),\n",
    "    (\"spark.shuffle.service.enabled\", \"true\"),\n",
    "    (\"spark.driver.memory\", \"12g\"),\n",
    "    (\"spark.dynamicAllocation.enabled\", \"true\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.setAppName(\"csv_conversion\").setMaster(\"yarn-client\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FNMA Spark -  Notebook 1\") \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_acq = [['LoanID', str],\n",
    "              ['Channel', str],\n",
    "              ['SellerName', str],\n",
    "              ['OrInterestRate', float],\n",
    "              ['OrUnpaidPrinc', int],\n",
    "              ['OrLoanTerm', int],\n",
    "              ['OrDate', str],\n",
    "              ['FirstPayment', str],\n",
    "              ['OrLTV', float],\n",
    "              ['OrCLTV', float],\n",
    "              ['NumBorrow', float],\n",
    "              ['DTIRat', float],\n",
    "              ['CreditScore', float],\n",
    "              ['FTHomeBuyer', str],\n",
    "              ['LoanPurpose', str],\n",
    "              ['PropertyType', str],\n",
    "              ['NumUnits', int],\n",
    "              ['OccStatus', str],\n",
    "              ['PropertyState', str],\n",
    "              ['Zip', int],\n",
    "              ['MortInsPerc', float],\n",
    "              ['ProductType', str],\n",
    "              ['CoCreditScore', float],\n",
    "              ['MortInsType', float],\n",
    "              ['RelMortInd', str]]\n",
    "schema_per = [['LoanID', str],\n",
    "              ['ReportingDate', str],\n",
    "              ['Servicer', str],\n",
    "              ['CurrInterestRate', float],\n",
    "              ['CAUPB', float],\n",
    "              ['LoanAge', int],\n",
    "              ['MonthsToMaturity', float],\n",
    "              ['AdMonthsToMaturity', float],\n",
    "              ['MaturityDate', str],\n",
    "              ['MSA', int],\n",
    "              ['CurDelStatus', str],\n",
    "              ['ModFlag', str],\n",
    "              ['ZeroBalCode', float],\n",
    "              ['ZeroBalEffDate', str],\n",
    "              ['LastInstallDate', str],\n",
    "              ['ForeclosureDate', str],\n",
    "              ['DispositionDate', str],\n",
    "              ['ForeclosureCost', float],\n",
    "              ['RepairCost', float],\n",
    "              ['AssetRecCost', float],\n",
    "              ['MiscCostsPF', float],\n",
    "              ['ATFHP', float],\n",
    "              ['NetSaleProceeds', float],\n",
    "              ['CreditEnhProceeds', float],\n",
    "              ['RPMWP', float],\n",
    "              ['OtherForePro', float],\n",
    "              ['NonInterestUPB', float],\n",
    "              ['PricipleForgiven', float],\n",
    "              ['RMWPF', str],\n",
    "              ['FPWA', float],\n",
    "              ['ServicingIndicator', str]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemap = {\n",
    "    str: StringType(),\n",
    "    float: FloatType(),\n",
    "    int: IntegerType()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Acquisition and Performance Datasets in spark sql\n",
    "schema_acq_spark = StructType([StructField(k, schemap[v], True) for k,v in schema_acq])\n",
    "schema_per_spark = StructType([StructField(k, schemap[v], True) for k,v in schema_per])\n",
    "\n",
    "acq = spark.read.load(\"/data/FNMA/Acquisition_2017Q1.txt\", format=\"csv\", header=\"false\",\n",
    "                     sep='|', schema=schema_acq_spark)\n",
    "\n",
    "per = spark.read.load(\"/data/FNMA/Performance_2017*.txt\", format=\"csv\", header=\"false\",\n",
    "                     sep='|', schema=schema_per_spark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining Acquisition and Performance Datasets from CSV in spark sql and saving the results to a csv file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "per = per.withColumn('date', F.to_date(per.ReportingDate, 'MM/dd/yyyy')) \\\n",
    "    .drop('ReportingDate') \\\n",
    "    .withColumnRenamed('date', 'ReportingDate') \\\n",
    "    .orderBy(\"LoanID\", F.desc(\"ReportingDate\")) \\\n",
    "    .dropDuplicates([\"LoanID\"])\n",
    "\n",
    "df = per.join(F.broadcast(acq), 'LoanID', 'outer').persist()\n",
    "\n",
    "#Converting the join dataframe to csv\n",
    "df.write.format('com.databricks.spark.csv').mode('overwrite').save('/data/FNMA/FNMA_2017_Join_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
